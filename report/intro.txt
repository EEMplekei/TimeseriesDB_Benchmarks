G


We have conducted a comprehensive exploration of the prominent database systems listed above, employing a robust benchmark suite renowned as TSBS, denoting the Time Series Benchmark Suite [1]. This suite encapsulates an assortment of Go programs and Shell scripts engineered to automate the benchmarking process for a specific category of databases. It ensures methodological coherence and comparability across a diverse array of scenarios. Leveraging the functionalities inherent in the TSBS tools, we generated three distinct datasets, distinguished by their varying magnitudes of size, labeled as small, medium, and large datasets. Subsequently, we ingested the generated data into both databases and assessed the relative performance of each database, discerning key metrics such as rows/sec and metrics/sec, which stand as universally acknowledged pivotal performance indicators for data ingestion.

Afterwards, we embarked on a study of how each database stores files on disk. This analytical endeavor involved the systematic identification of on-disk database files, precise measurement of file sizes for each database, and a analysis of diverse compression techniques, especially pertinent when dealing with time-series data. Having prepared the databases and measured insert performance, we proceeded to formulate an array of query scenarios, spanning the testing spectrum from one query to multiple protracted queries.

With the queries systematically generated and organized within well-structured directories, a plan was devised for querying the databases and consolidating results for each scenario. To uphold the highest standards of accuracy, a steadfast protocol was adhered to, involving the systematic clearance of the cache at the initiation of every new query or query-set execution. Subsequently, queries were executed under diverse scenarios and infrastructures, encompassing tests on both single and multi-node architectures. The latter aspect, focusing on tests conducted with increased data-node count, furnished valuable insights into the scalability and responsiveness of the databases.

To systematically analyze and visually represent the results amassed from multiple benchmarks, we crafted a series of diagrams using Python scripts REF(https://github.com/EEMplekei/TimeseriesDB_Benchmarks/tree/main/single_node/scripts). In the conclusive section of this document, we critically study the outcomes derived from the TSBS benchmark, shedding light on the distinctive advantages that one database holds over the other.