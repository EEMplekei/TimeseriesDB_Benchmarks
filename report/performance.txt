PERFORMANCE EVALUATION: DISK SIZE 
Upon the completion of data insertion into each respective database and subsequent collection of results, our inquiry advanced to a comparative assessment of the database files stored on disk, with particular attention given to the compression strategies employed by the two databases. This becomes imperative when managing an array of rapidly accumulating daily timestamped measurements.

The storage engine that powered InfluxDB 1.x and 2.x was called the InfluxDB Time-Structured Merge Tree (TSM) that resembles a LSM Tree (a data structure with performance characteristics that make it suitable for providing indexed access to files with high insert volume). TSM uses run length encoding for compression. This approach is very efficient for metrics use cases where data timestamps occurred at regular intervals. InfluxDB was able to store the starting time and time interval, and then calculate each time stamp at query time, based on only row count. Additionally, the TSM engine could use run length encoding on the actual field data. So, in cases where data did not change frequently and the timestamps were regular, InfluxDB could compress data very efficiently. However, use cases with irregular timestamp intervals, or where the data changed with nearly every reading, reduced the effectiveness of compression.
Additional insights into the intelligent and efficient methodology employed by Influx's storage engine to process incoming data can be found [here]. A visual demonstration of our assertions is evident in the graph presented below, highlighting Influx's adeptness in achieving surprising compact database disk sizes. Notably, in datasets of 1 GB, 5 GB, and 15 GB sizes, Influx demonstrates an impressive storage efficiency, realizing respective sizes of 0.15 GB, 0.56 GB, and 1.5 GB.

In contrast TimescaleDB, by default, opts for a strategy of not applying compression to stored data. This choice aligns with the philosophy of prioritizing performance and minimizing computational overhead during data storage operations. By abstaining from compression as the default setting, TimescaleDB perhaps aims to streamline write operations and maintain responsiveness, especially in scenarios involving high-volume time-series data. The rationale behind this decision is rooted in the acknowledgment that compression introduces additional processing overhead during data writes and could potentially impact the speed of data ingestion. By favoring a non-compressed storage approach by default, TimescaleDB provides users with the flexibility to fine-tune compression settings based on their specific use cases, ensuring optimal performance tailored to individual requirements. 
The decision by TimescaleDB to abstain from data compression is depicted in the ensuing graphical representation, wherein the sizes of databases for each dataset markedly exceed those of InfluxDB and, notably, surpass the sizes of the datasets themselves. Concretely, the Timescale database allocated 1.14 GB for a small dataset of 1 GB, 5.69 GB for a medium dataset of 5 GB, and 17.16 GB for a large dataset of 15 GB. This outcome underscores the impact of TimescaleDB's uncompressed default setting on the resulting database sizes, revealing a notable divergence from the more compact storage achieved by InfluxDB.

While it may appear somewhat inequitable to TimescaleDB in the context of disk size comparison, we have chosen to proceed with the entire evaluation using the default settings of each database â€“ wherein InfluxDB employs compression, while TimescaleDB refrains from doing so. We posit that, despite an initial impression of an unconventional comparison, each database is intricately optimized for its default settings. The perceived disadvantage concerning disk sizes is anticipated to be offset by potential gains in processing speed operations. This strategic decision aligns with the premise that default configurations are tailored to achieve optimal performance within the intended operational parameters of each respective database system.

In order to measure disk size we use "du" command with root privileges which is a standard Linux/Unix command that allows a user to gain disk usage information. 
Postgres which is the underlying database for TimescaleDB extension uses the directory:
    var/lib/postgresql/14/main/base
to store database files inside directories with numeric names (e.g. 34250). This numeric value is called OID and is a data type which PostgreSQL uses as a unique identifier (primary key) for database objects. The OID data type is implemented as an unsigned 32 bit integer.

Influxdb uses the directory "var/lib/influxdb/data" and stores database files inside directories with the DATA_BASE_NAME as name.


[https://www.influxdata.com/blog/improved-data-ingest-compression-influxdb-3-0/ ]
[ https://docs.influxdata.com/influxdb/v1/concepts/storage_engine/?_gl=1*1vpjfok*_ga*Mzk3ODQ1Njg2LjE3MDQ3OTMzODc.*_ga_CNWQ54SDD8*MTcwNTQ4MzE1OC4xNS4wLjE3MDU0ODMxNTguNjAuMC4w ]

PERFORMANCE EVALUATION: WRITE OPERATIONS

To assess the insertion performance of each database, we employed bash scripts, supplied by TSBS (Time Series Benchmark Suite). Specifically load_timescaledb.sh REF(REPO/TimeseriesDB_Benchmarks/single_node/data_load) and load_influx.sh REF(REPO/TimeseriesDB_Benchmarks/single_node/data_load) are used to parameterize and execute the tsbs_load_timescaledb and tsbs_load_influx Go binaries.

For load_timescaledb, the initial modification involves adjusting the DATA_FILE_NAME environment variable to specify the desired file for insertion. Subsequently, relevant PostgreSQL authentication environment variables are adjusted: DATA_BASE_USER_NAME, DATA_BASE_NAME, DATA_BASE_HOST, DATA_BASE_PORT, DATA_BASE_PASSWORD

Before executing the script, the BULK_DATA_DIR variable in load_common.sh REF(REPO/TimeseriesDB_Benchmarks/single_node/data_load) must be updated to point to the directory containing the generated data. In our case:
BULK_DATA_DIR = /home/ubuntu/TimeseriesDB_Benchmarks/single_node/iot_data

The required modifications for running the load_influx.sh script mirror those for load_timescaledb with the only exception being, in the case of Influx, the password variable is not required.

We then analyzed the generated output files and generated performance graphs, utilizing a Python script to compare the ingestion rates in rows per second and metrics per second for each database at different sizes. The results are visually depicted below:

[PNG as result of the execution script: python3 /TimeseriesDB_Benchmarks/single_node/scripts/graph_write_performance.py]

In the context of performance insertion metrics:
- Rows/s (Rows per Second): This metric indicates the rate at which individual rows or data points are being ingested, processed, or queried in the database.
- Metrics/s (Metrics per Second): This metric refers to the rate at which sets of values or measurements (metrics) are being processed. It's a higher-level metric that accounts for the fact that each row may contain multiple values or dimensions.

In terms of rows rate, Timescale demonstrates a peak performance for medium dataset sizes, reaching 57.99K rows/sec. In comparison, InfluxDB exhibits a noticeable reduction at 45.66K rows/sec for the same dataset, reflecting a substantial decrease of 21%. In scenarios involving smaller datasets, the disparity between the two databases diminishes, with TimescaleDB achieving a rate of 51.12K rows/sec and InfluxDB registering 49.19K rows/sec. In the context of larger datasets, the performance differential lies between the two aforementioned scenarios, with a discernible difference of approximately 17%.

Regarding the metric rate, InfluxDB consistently surpasses TimescaleDB, exhibiting a substantial increment across all datasets. In particular, InfluxDB attains its zenith at 388.87K metrics/sec for the small dataset, displaying a marginal reduction as the scale of the database expands by an order of magnitude. Conversely, TimescaleDB, while manifesting comparatively smaller peaks, demonstrates commendable proficiency in maintaining a consistent or enhanced ingestion rate as the database size increases, in stark contrast to the deceleration observed in InfluxDB. 

The distinct nature of InfluxDB and PostgreSQL/TimescaleDB is evident from the depicted graph. InfluxDB is specifically engineered for the continuous ingestion of metrics, exhibiting prowess in managing high-frequency, real-time data influx within the domain of time-series data. Its storage engine and query language are optimized for this continuous ingestion pattern, making it well-suited for scenarios where new data points are arriving frequently.
In contrast, Timescale (as a PostgreSQL extension) follows a row-based approach to data storage and ingestion. Although TimescaleDB is finely tuned for time-series data and incorporates extensions aimed at augmenting performance within such workloads, it remains steadfast in its adherence to the relational model. This adherence underscores the methodical insertion of data into the database structure as individual rows, aligning with conventional relational database practices.

It is imperative to acknowledge that, as elucidated in the former section concerning disk sizes, our methodology involves adhering to the default compression configurations implemented by TimescaleDB and InfluxDB. Notably, InfluxDB employs a data compression mechanism, while TimescaleDB does not. This intrinsic discrepancy in compression methodologies likely contributes to the fact that TimescaleDB can sustain a more consistent or augmented insertion rate. In contrast, InfluxDB exhibits a reduction in performance as the database size expands, potentially indicative of an increased cost associated with compression in the context of larger datasets, as opposed to their smaller counterparts.

PERFORMANCE EVALUATION: AVERAGE QUERY EXECUTION
To quantify query performance across each database, we systematically gather data and construct bar graphs encompassing two distinct scenarios. The initial scenario involves the execution of a singular query per query type, with subsequent computation of the average execution time. The second scenario entails the execution of ten consecutive queries per query type. The ensuing graphs visually present the mean execution time for all query types across the three distinct datasets (small, medium, large) under both scenarios.
A concise analysis detailing the comparative efficiency of databases in handling aggregates, joins, and simple projections will be expounded upon shortly towards the conclusion of this section analyzing briefly the performance for every query type.

Initially, subtle disparities are observed between the executions for single and ten queries per type. The primary distinction manifests in a marginal convergence between the two databases, namely Influx and Timescale. However, the temporal differential in large datasets continues to exhibit substantial levels.

Both graphical representations depict that for small and medium datasets, distinctions between the two databases are less pronounced. Nevertheless, concerning large datasets, the disparity intensifies significantly, with Influx surpassing Timescale in performance. This observation contrasts with findings from publicly available benchmarks. Existing researches suggests that InfluxDB excels in smaller databases, with its performance markedly deteriorating as data sizes increase, where Timescale outperforms REF[https://medium.com/timescale/timescaledb-vs-influxdb-for-time-series-data-timescale-influx-sql-nosql-36489299877]. However, it is worth noting that the limitations of our hardware resources, encompassing CPU, memory, and disk storage, may constrain our ability to scale up data and conduct experiments as the dataset size really expands. Despite our limitations we should confine our analysis to the observations discerned from our graphical representations.

Therefore, our graphs reveal that Influx, particularly with our large database, consistently outperforms Timescale, primarily attributable to three specific query types whose execution durations are notably prolonged in TimescaleDB. Further elaboration on the execution of these individual query types and briefly analysis for the execution of each query type will be provided in an upcoming section.
